{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as text\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, Dense, Bidirectional, LSTM, GlobalAveragePooling1D, GlobalMaxPooling1D, Dropout, concatenate\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, classification_report, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Importing Data\n",
      "\t1 pairs of good English-French files found.\n",
      "\t1 pairs of bad English-French files found.\n",
      "Importing Data Complete.\n",
      "\t17719 good entries\n",
      "\t3147 bad entries\n",
      "\n",
      "Train samples : 16692\n",
      "Test samples  : 4174\n",
      "\n",
      "Train samples : 15022\n",
      "Test samples  : 1670\n",
      "\n",
      "Importing Data\n",
      "\t0 pairs of good English-French files found.\n",
      "\t1 pairs of bad English-French files found.\n",
      "Importing Data Complete.\n",
      "\t0 good entries\n",
      "\t2499 bad entries\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import TextPreprocess\n",
    "\n",
    "# srcLang = \"eng\"\n",
    "# tgtLang = \"fra\"\n",
    "# src_vocab_size = 20000\n",
    "# src_len = 150\n",
    "# tgt_vocab_size = 20000\n",
    "# tgt_len = 150\n",
    "train_data_dir = \"/linguistics/ethan/DL_Prototype/datasets/TB_TQA/tb_train_cleaned\"\n",
    "synthetic_data_dir = \"/linguistics/ethan/DL_Prototype/datasets/TB_TQA/synthetic/mix_gender_replace_article_delete_2500\"\n",
    "label_class_map = {\"good\": 1, \"bad\": 0}\n",
    "tp = TextPreprocess()\n",
    "train_dataset, test_dataset = tp.create_datasets(\n",
    "                                                train_data_dir,\n",
    "                                                label_class_map,\n",
    "                                                train_test_split_train_ratio=0.8,\n",
    "                                                data_generator=False,\n",
    "                                                batch_size=32,\n",
    "                                                num_classes=2,\n",
    "                                                onehot_encoding=False,\n",
    "                                                shuffle=True,\n",
    "                                                random_state=1)\n",
    "\n",
    "train_dataset, val_dataset = tp.train_test_split(train_dataset[0][0],\n",
    "                                                 train_dataset[0][1],\n",
    "                                                 train_dataset[1],\n",
    "                                                 train_ratio=0.9)\n",
    "\n",
    "syn_src, syn_tgt, syn_labels = tp.read_dataset_from_directory(synthetic_data_dir,\n",
    "                                                              label_class_map,\n",
    "                                                              shuffle=True,\n",
    "                                                              random_state=1,\n",
    "                                                              drop_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"merge training data with synthetic data, make sure to shuffle data again after merging.\"\"\"\n",
    "INCLUDE_SYNTHETIC = False\n",
    "\n",
    "unique_classes = np.array([0, 1])\n",
    "\n",
    "if INCLUDE_SYNTHETIC:\n",
    "    train_src_text = np.array(list(train_dataset[0][0]) + list(syn_src))\n",
    "    train_tgt_text = np.array(list(train_dataset[0][1]) + list(syn_tgt))\n",
    "    train_labels = np.array(list(train_dataset[1]) + list(syn_labels))\n",
    "\n",
    "    train_src_text, train_tgt_text, train_labels = tp.suffle_data(train_src_text,\n",
    "                                                                  train_tgt_text,\n",
    "                                                                  train_labels,\n",
    "                                                                  random_state=1)\n",
    "\n",
    "    # train_labels = train_dataset[1]\n",
    "    weights = compute_class_weight(\"balanced\", unique_classes, train_labels)\n",
    "\n",
    "    print(\"Total training samples after addin synthetic data: {}\".format(len(train_labels)))\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_src_text\": train_src_text,\n",
    "                                                         \"input_tgt_text\": train_tgt_text},\n",
    "                                                        train_labels)).batch(32)\n",
    "\n",
    "else:\n",
    "    weights = compute_class_weight(\"balanced\", unique_classes, train_dataset[1])\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(({\"input_src_text\": train_dataset[0][0],\n",
    "                                                     \"input_tgt_text\": train_dataset[0][1]},\n",
    "                                                    train_dataset[1])).batch(32)\n",
    "\n",
    "class_weight = dict(zip(unique_classes, weights)) \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(({\"input_src_text\": val_dataset[0][0],\n",
    "                                                   \"input_tgt_text\": val_dataset[0][1]},\n",
    "                                                  val_dataset[1])).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(train_src_text))\n",
    "# print(len(set(zip(train_src_text, train_tgt_text))))\n",
    "# print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17521"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[-100: ]\n",
    "class_weight\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instances, labels in train_dataset.take(1):\n",
    "    print(instances)\n",
    "    print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilingual_LaBSE_FF(preprocessor_dir, LaBSE_dir):\n",
    "    \n",
    "    src_texts = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_src_text\")\n",
    "    tgt_texts = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_tgt_text\")\n",
    "\n",
    "    preprocessor = hub.KerasLayer(preprocessor_dir, trainable=False)\n",
    "    encoder = hub.KerasLayer(LaBSE_dir, trainable=False)\n",
    "    \n",
    "    src_x = preprocessor(src_texts)\n",
    "    tgt_x = preprocessor(tgt_texts)\n",
    "    \n",
    "    src_x = encoder(src_x)[\"default\"]\n",
    "    tgt_x = encoder(tgt_x)[\"default\"]\n",
    "    \n",
    "    src_x = tf.math.l2_normalize(src_x, axis=1, epsilon=1e-12, name=None)\n",
    "    tgt_x = tf.math.l2_normalize(tgt_x, axis=1, epsilon=1e-12, name=None)\n",
    "    \n",
    "    # np.matmul(english_embeds, np.transpose(italian_embeds))\n",
    "    x = tf.concat([src_x, tgt_x], axis=1)\n",
    "    #  x = GlobalMaxPooling1D(x)\n",
    "\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(8, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model([src_texts, tgt_texts], output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def multilingual_LaBSE_BiLSTM(preprocessor_dir, LaBSE_dir):\n",
    "    \n",
    "    src_texts = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_src_text\")\n",
    "    tgt_texts = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_tgt_text\")\n",
    "\n",
    "    preprocessor = hub.KerasLayer(preprocessor_dir, trainable=False)\n",
    "    encoder = hub.KerasLayer(LaBSE_dir, trainable=False)\n",
    "    \n",
    "    src_x = preprocessor(src_texts)\n",
    "    tgt_x = preprocessor(tgt_texts)\n",
    "    \n",
    "    src_x = encoder(src_x)[\"sequence_output\"]\n",
    "    tgt_x = encoder(tgt_x)[\"sequence_output\"]\n",
    "    \n",
    "    src_x = tf.math.l2_normalize(src_x, axis=1, epsilon=1e-12, name=None)\n",
    "    tgt_x = tf.math.l2_normalize(tgt_x, axis=1, epsilon=1e-12, name=None)\n",
    "    \n",
    "    x = tf.concat([src_x, tgt_x], axis=-1)\n",
    "    \n",
    "    bi_lstm = Bidirectional(LSTM(768, return_sequences=True))(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(bi_lstm)\n",
    "    max_pool = GlobalMaxPooling1D()(bi_lstm)\n",
    "    concat = concatenate([avg_pool, max_pool])\n",
    "    dropout = Dropout(0.3)(concat)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(dropout)\n",
    "    model = Model([src_texts, tgt_texts], output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def multilingual_LaBSE_2BiLSTM_FF(preprocessor_dir, LaBSE_dir, max_len):\n",
    "    \n",
    "    src_texts = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_src_text\")\n",
    "    tgt_texts = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"input_tgt_text\")\n",
    "\n",
    "    preprocessor = hub.KerasLayer(preprocessor_dir, trainable=False)\n",
    "    encoder = hub.KerasLayer(LaBSE_dir, trainable=False)\n",
    "    \n",
    "    src_x = preprocessor(src_texts)\n",
    "    tgt_x = preprocessor(tgt_texts)\n",
    "    \n",
    "    src_x = encoder(src_x)[\"sequence_output\"]\n",
    "    tgt_x = encoder(tgt_x)[\"sequence_output\"]\n",
    "    \n",
    "    src_x = src_x[:, :max_len, :]\n",
    "    tgt_x = tgt_x[:, :max_len, :]\n",
    "    \n",
    "    src_x = tf.math.l2_normalize(src_x, axis=-1, epsilon=1e-12, name=None)\n",
    "    tgt_x = tf.math.l2_normalize(tgt_x, axis=-1, epsilon=1e-12, name=None)\n",
    "    \n",
    "    src_bi_lstm = Bidirectional(LSTM(128, return_sequences=True), name=\"src_bi_lstm\")(src_x)\n",
    "    tgt_bi_lstm = Bidirectional(LSTM(128, return_sequences=True), name=\"tgt_bi_lstm\")(tgt_x)\n",
    "    \n",
    "    src_avg_pool = GlobalAveragePooling1D(name=\"src_global_avg_pooling\")(src_bi_lstm)\n",
    "    tgt_avg_pool = GlobalAveragePooling1D(name=\"tgt_global_avg_pooling\")(tgt_bi_lstm)\n",
    "    \n",
    "    concat = concatenate([src_avg_pool, tgt_avg_pool])\n",
    "    dropout = Dropout(0.3)(concat)\n",
    "    x = Dense(64, activation=\"relu\")(dropout)\n",
    "    \n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model([src_texts, tgt_texts], output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Hyper-parameter settings\"\"\"\n",
    "\n",
    "epochs = 15\n",
    "max_len = 10\n",
    "loss_fn = \"binary_crossentropy\"\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=learning_rate/epochs)\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "preprocessor_dir = \"/linguistics/ethan/DL_Prototype/models/universal-sentence-encoder-cmlm_multilingual-preprocess_2\"\n",
    "LaBSE_dir = \"/linguistics/ethan/DL_Prototype/models/LaBSE2_encoder\"\n",
    "\n",
    "checkpoint_path = \"/linguistics/ethan/DL_Prototype/models/TBqa/3.3.Multilingual-LaBSE-BiLSTM-movingLR-original-data/tqc-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "ckpt_callback = ModelCheckpoint(checkpoint_path, \n",
    "                           save_best_only=True,\n",
    "                           save_weights_only=True,\n",
    "                           monitor=\"val_accuracy\",\n",
    "                           mode=\"max\",\n",
    "                           save_freq='epoch') # Save weights, every epoch.\n",
    "tensorboard_callback = TensorBoard(log_dir=checkpoint_path, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_src_text (InputLayer)     [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_tgt_text (InputLayer)     [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        {'input_word_ids': ( 0           input_src_text[0][0]             \n",
      "                                                                 input_tgt_text[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer_1 (KerasLayer)      {'pooled_output': (N 470926849   keras_layer[0][0]                \n",
      "                                                                 keras_layer[0][1]                \n",
      "                                                                 keras_layer[0][2]                \n",
      "                                                                 keras_layer[1][0]                \n",
      "                                                                 keras_layer[1][1]                \n",
      "                                                                 keras_layer[1][2]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square (TensorFlowO [(None, None, 768)]  0           keras_layer_1[0][14]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_1 (TensorFlo [(None, None, 768)]  0           keras_layer_1[1][14]             \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum (TensorFlowOpLa [(None, 1, 768)]     0           tf_op_layer_Square[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sum_1 (TensorFlowOp [(None, 1, 768)]     0           tf_op_layer_Square_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Maximum (TensorFlow [(None, 1, 768)]     0           tf_op_layer_Sum[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Maximum_1 (TensorFl [(None, 1, 768)]     0           tf_op_layer_Sum_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Rsqrt (TensorFlowOp [(None, 1, 768)]     0           tf_op_layer_Maximum[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Rsqrt_1 (TensorFlow [(None, 1, 768)]     0           tf_op_layer_Maximum_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul (TensorFlowOpLa [(None, None, 768)]  0           keras_layer_1[0][14]             \n",
      "                                                                 tf_op_layer_Rsqrt[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_1 (TensorFlowOp [(None, None, 768)]  0           keras_layer_1[1][14]             \n",
      "                                                                 tf_op_layer_Rsqrt_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_concat (TensorFlowO [(None, None, 1536)] 0           tf_op_layer_Mul[0][0]            \n",
      "                                                                 tf_op_layer_Mul_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, None, 1536)   14161920    tf_op_layer_concat[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 1536)         0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 1536)         0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3072)         0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 3072)         0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            3073        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 485,091,842\n",
      "Trainable params: 14,164,993\n",
      "Non-trainable params: 470,926,849\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /linguistics/ethan/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 8 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "470/470 [==============================] - ETA: 0s - loss: 0.3984 - accuracy: 0.8078INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "470/470 [==============================] - 92s 195ms/step - loss: 0.3984 - accuracy: 0.8078 - val_loss: 0.3073 - val_accuracy: 0.8527\n",
      "Epoch 2/15\n",
      "470/470 [==============================] - 84s 178ms/step - loss: 0.2930 - accuracy: 0.8579 - val_loss: 0.2905 - val_accuracy: 0.8790\n",
      "Epoch 3/15\n",
      "470/470 [==============================] - 85s 180ms/step - loss: 0.2313 - accuracy: 0.8905 - val_loss: 0.2700 - val_accuracy: 0.8820\n",
      "Epoch 4/15\n",
      "470/470 [==============================] - 86s 184ms/step - loss: 0.1713 - accuracy: 0.9179 - val_loss: 0.2631 - val_accuracy: 0.8916\n",
      "Epoch 5/15\n",
      "470/470 [==============================] - 83s 177ms/step - loss: 0.1417 - accuracy: 0.9317 - val_loss: 0.3102 - val_accuracy: 0.8874\n",
      "Epoch 6/15\n",
      "470/470 [==============================] - 84s 179ms/step - loss: 0.1129 - accuracy: 0.9481 - val_loss: 0.3765 - val_accuracy: 0.8635\n",
      "Epoch 7/15\n",
      "470/470 [==============================] - 88s 188ms/step - loss: 0.0757 - accuracy: 0.9678 - val_loss: 0.3879 - val_accuracy: 0.8976\n",
      "Epoch 8/15\n",
      "470/470 [==============================] - 88s 187ms/step - loss: 0.0639 - accuracy: 0.9728 - val_loss: 0.5400 - val_accuracy: 0.8994\n",
      "Epoch 9/15\n",
      "470/470 [==============================] - 88s 188ms/step - loss: 0.0530 - accuracy: 0.9777 - val_loss: 0.5172 - val_accuracy: 0.9036\n",
      "Epoch 10/15\n",
      "470/470 [==============================] - 89s 189ms/step - loss: 0.0463 - accuracy: 0.9812 - val_loss: 0.5379 - val_accuracy: 0.9060\n",
      "Epoch 11/15\n",
      "470/470 [==============================] - 84s 179ms/step - loss: 0.0428 - accuracy: 0.9837 - val_loss: 0.4864 - val_accuracy: 0.9060\n",
      "Epoch 12/15\n",
      "470/470 [==============================] - 85s 180ms/step - loss: 0.0357 - accuracy: 0.9870 - val_loss: 0.4785 - val_accuracy: 0.8922\n",
      "Epoch 13/15\n",
      "470/470 [==============================] - 84s 180ms/step - loss: 0.0284 - accuracy: 0.9895 - val_loss: 0.4815 - val_accuracy: 0.8910\n",
      "Epoch 14/15\n",
      "470/470 [==============================] - 85s 181ms/step - loss: 0.0241 - accuracy: 0.9911 - val_loss: 0.4802 - val_accuracy: 0.9024\n",
      "Epoch 15/15\n",
      "470/470 [==============================] - 85s 181ms/step - loss: 0.0213 - accuracy: 0.9915 - val_loss: 0.5379 - val_accuracy: 0.9030\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:5\", \"/gpu:6\", \"/gpu:7\"])\n",
    "with mirrored_strategy.scope():\n",
    "    tqc = multilingual_LaBSE_BiLSTM(preprocessor_dir, LaBSE_dir)\n",
    "    #  tqc = multilingual_LaBSE_2BiLSTM_FF(preprocessor_dir, LaBSE_dir, max_len=128)\n",
    "    print(tqc.summary())\n",
    "    tqc.compile(optimizer=optimizer,\n",
    "                loss=loss_fn,\n",
    "                metrics=metrics)\n",
    "    tqc.fit(\n",
    "            train_dataset,\n",
    "            validation_data=val_dataset,\n",
    "            epochs=epochs,\n",
    "            callbacks=[ckpt_callback],\n",
    "            class_weight=class_weight\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/gpu:6\"):\n",
    "    #  tqc = multilingual_LaBSE_BiLSTM(preprocessor_dir, LaBSE_dir)\n",
    "    tqc = multilingual_LaBSE_2BiLSTM_FF(preprocessor_dir, LaBSE_dir, max_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqc.summary()\n",
    "# tf.keras.utils.plot_model(tqc, \"./model4.2.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(test_dataset[1] == preds.reshape(-1,))[:50]\n",
    "# print(test_dataset[1][:11])\n",
    "# print(preds.reshape(-1,)[:11])\n",
    "# test_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqc.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f0dfc707c10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Save and load model\"\"\"\n",
    "model_dir = \"/linguistics/ethan/DL_Prototype/models/TBqa/3.3.Multilingual-LaBSE-BiLSTM-movingLR-original-data/tqc-0010.ckpt\"\n",
    "# tqc.save(model_dir)\n",
    "# mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:5\", \"/gpu:6\", \"/gpu:7\"])\n",
    "# with mirrored_strategy.scope():\n",
    "#     tqc = tf.keras.models.load_model(model_dir)\n",
    "tqc.load_weights(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_misclassified_examples(y_true, y_pred, examples, output_file):\n",
    "\n",
    "    misclassified_index = y_true != y_pred\n",
    "    #  print(misclassified_index)\n",
    "    src_terms = examples[0][misclassified_index]\n",
    "    tgt_terms = examples[1][misclassified_index]\n",
    "    true_labels = y_true[misclassified_index]\n",
    "    pred_labels = y_pred[misclassified_index]\n",
    "    df = pd.DataFrame({\"source\": src_terms, \"target\": tgt_terms,\n",
    "                       \"true_label\": true_labels, \"pred_label\": pred_labels})\n",
    "    # print(df)\n",
    "    df.to_excel(output_file, header=True, index=None)\n",
    "\n",
    "output_file = \"/linguistics/ethan/DL_Prototype/TB_quality_assessor.misclassified.xlsx\"\n",
    "output_misclassified_examples(test_dataset[1], preds.reshape(-1, ), test_dataset[0], output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tqc.predict(list(test_dataset[0]))\n",
    "preds = np.where(predictions > 0.5, 1, 0).reshape(-1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.where(predictions > 0.5, 1, 0)\n",
    "# cm = confusion_matrix(test_dataset[1], preds)\n",
    "# sns.heatmap(cm, annot=True)\n",
    "# sns.heatmap(cm/np.sum(cm), annot=True, fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       606\n",
      "           1       0.95      0.96      0.95      3568\n",
      "\n",
      "    accuracy                           0.92      4174\n",
      "   macro avg       0.85      0.83      0.84      4174\n",
      "weighted avg       0.92      0.92      0.92      4174\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    df_cm = pd.DataFrame(cm/np.sum(cm), columns=np.unique(y_true), index=np.unique(y_true))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    plt.figure(figsize = (10,7))\n",
    "    # sns.set(font_scale=1.4)#for label size\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True, fmt='.2%', annot_kws={\"size\": 16})\n",
    "    #print(\"\\nAccuracy: {}\".format(accuracy_score(y_true, y_pred)))\n",
    "    #print(\"Recall: {}\".format(recall_score(y_true, y_pred)))\n",
    "    #print(\"precision: {}\".format(precision_score(y_true, y_pred)))\n",
    "    #print(\"f1: {}\".format(f1_score(y_true, y_pred)))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "plot_confusion_matrix(test_dataset[1], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.63      0.70       606\n",
      "           1       0.94      0.97      0.95      3568\n",
      "\n",
      "    accuracy                           0.92      4174\n",
      "   macro avg       0.86      0.80      0.83      4174\n",
      "weighted avg       0.92      0.92      0.92      4174\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(test_dataset[1], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall_0</th>\n",
       "      <th>Precision_0</th>\n",
       "      <th>F1_0</th>\n",
       "      <th>Recall_1</th>\n",
       "      <th>Precision_1</th>\n",
       "      <th>F1_1</th>\n",
       "      <th>Roc-Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.920903</td>\n",
       "      <td>0.981559</td>\n",
       "      <td>0.929365</td>\n",
       "      <td>0.954749</td>\n",
       "      <td>0.981559</td>\n",
       "      <td>0.929365</td>\n",
       "      <td>0.954749</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.920903</td>\n",
       "      <td>0.967868</td>\n",
       "      <td>0.940793</td>\n",
       "      <td>0.954139</td>\n",
       "      <td>0.967868</td>\n",
       "      <td>0.940793</td>\n",
       "      <td>0.954139</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.918765</td>\n",
       "      <td>0.958648</td>\n",
       "      <td>0.946483</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>0.958648</td>\n",
       "      <td>0.946483</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.914727</td>\n",
       "      <td>0.948310</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>0.949769</td>\n",
       "      <td>0.948310</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>0.949769</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.912827</td>\n",
       "      <td>0.939648</td>\n",
       "      <td>0.957029</td>\n",
       "      <td>0.948259</td>\n",
       "      <td>0.939648</td>\n",
       "      <td>0.957029</td>\n",
       "      <td>0.948259</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.911164</td>\n",
       "      <td>0.932383</td>\n",
       "      <td>0.961949</td>\n",
       "      <td>0.946935</td>\n",
       "      <td>0.932383</td>\n",
       "      <td>0.961949</td>\n",
       "      <td>0.946935</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.905938</td>\n",
       "      <td>0.920648</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.943315</td>\n",
       "      <td>0.920648</td>\n",
       "      <td>0.967127</td>\n",
       "      <td>0.943315</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.892399</td>\n",
       "      <td>0.899693</td>\n",
       "      <td>0.971635</td>\n",
       "      <td>0.934281</td>\n",
       "      <td>0.899693</td>\n",
       "      <td>0.971635</td>\n",
       "      <td>0.934281</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.867458</td>\n",
       "      <td>0.866443</td>\n",
       "      <td>0.974851</td>\n",
       "      <td>0.917456</td>\n",
       "      <td>0.866443</td>\n",
       "      <td>0.974851</td>\n",
       "      <td>0.917456</td>\n",
       "      <td>0.948422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Threshold  Accuracy  Recall_0  Precision_0      F1_0  Recall_1  \\\n",
       "0        0.1  0.920903  0.981559     0.929365  0.954749  0.981559   \n",
       "1        0.2  0.920903  0.967868     0.940793  0.954139  0.967868   \n",
       "2        0.3  0.918765  0.958648     0.946483  0.952526  0.958648   \n",
       "3        0.4  0.914727  0.948310     0.951233  0.949769  0.948310   \n",
       "4        0.5  0.912827  0.939648     0.957029  0.948259  0.939648   \n",
       "5        0.6  0.911164  0.932383     0.961949  0.946935  0.932383   \n",
       "6        0.7  0.905938  0.920648     0.967127  0.943315  0.920648   \n",
       "7        0.8  0.892399  0.899693     0.971635  0.934281  0.899693   \n",
       "8        0.9  0.867458  0.866443     0.974851  0.917456  0.866443   \n",
       "\n",
       "   Precision_1      F1_1   Roc-Auc  \n",
       "0     0.929365  0.954749  0.948422  \n",
       "1     0.940793  0.954139  0.948422  \n",
       "2     0.946483  0.952526  0.948422  \n",
       "3     0.951233  0.949769  0.948422  \n",
       "4     0.957029  0.948259  0.948422  \n",
       "5     0.961949  0.946935  0.948422  \n",
       "6     0.967127  0.943315  0.948422  \n",
       "7     0.971635  0.934281  0.948422  \n",
       "8     0.974851  0.917456  0.948422  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tqc.summary()\n",
    "# for i, data in enumerate(train_dataset):\n",
    "#     print(i)\n",
    "\n",
    "def evaluate(predictions, true_labels, labels):\n",
    "    records = []\n",
    "    for threshold in np.linspace(0.1, 0.9, num=9):\n",
    "        pred = [1 if p > threshold else 0 for p in predictions]\n",
    "        acc = accuracy_score(true_labels, pred)\n",
    "        rec_0 = recall_score(true_labels, pred, labels=[0,1])\n",
    "        pre_0 = precision_score(true_labels, pred, labels=[0,1])\n",
    "        f1_0 = f1_score(true_labels, pred, labels=[0,1])\n",
    "        \n",
    "        rec_1 = recall_score(true_labels, pred, labels=[1,0])\n",
    "        pre_1 = precision_score(true_labels, pred, labels=[1,0])\n",
    "        f1_1 = f1_score(true_labels, pred, labels=[1,0])\n",
    "        roc_auc = roc_auc_score(true_labels, predictions)\n",
    "        records.append((threshold, acc, rec_0, pre_0, f1_0, rec_1, pre_1, f1_1, roc_auc))\n",
    "\n",
    "        df = pd.DataFrame(records, columns=[\"Threshold\", \"Accuracy\", \n",
    "                                            \"Recall_0\", \"Precision_0\", \"F1_0\", \n",
    "                                            \"Recall_1\", \"Precision_1\", \"F1_1\",\n",
    "                                            \"Roc-Auc\"])\n",
    "    return df\n",
    "\n",
    "evaluate(predictions, test_dataset[1], labels=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Compute LaBSE output\"\"\"\n",
    "import bert\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "def get_model(model_url, max_seq_length):\n",
    "    \n",
    "    labse_layer = hub.KerasLayer(model_url, trainable=False)\n",
    "\n",
    "      # Define input.\n",
    "    input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                             name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                     name=\"input_mask\")\n",
    "    segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
    "                                      name=\"segment_ids\")\n",
    "\n",
    "    # LaBSE layer.\n",
    "    pooled_output,  _ = labse_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "    # The embedding is l2 normalized.\n",
    "    pooled_output = tf.keras.layers.Lambda(\n",
    "      lambda x: tf.nn.l2_normalize(x, axis=1))(pooled_output)\n",
    "\n",
    "    # Define model.\n",
    "    return tf.keras.Model(inputs=[input_word_ids, input_mask, segment_ids],\n",
    "                          outputs=pooled_output), labse_layer\n",
    "\n",
    "def create_input(input_strings, tokenizer, max_seq_length):\n",
    "\n",
    "    input_ids_all, input_mask_all, segment_ids_all = [], [], []\n",
    "    for input_string in input_strings:\n",
    "        # Tokenize input.\n",
    "        input_tokens = [\"[CLS]\"] + tokenizer.tokenize(input_string) + [\"[SEP]\"]\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(input_tokens)\n",
    "        sequence_length = min(len(input_ids), max_seq_length)\n",
    "\n",
    "        # Padding or truncation.\n",
    "        if len(input_ids) >= max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "        else:\n",
    "            input_ids = input_ids + [0] * (max_seq_length - len(input_ids))\n",
    "\n",
    "        input_mask = [1] * sequence_length + [0] * (max_seq_length - sequence_length)\n",
    "\n",
    "        input_ids_all.append(input_ids)\n",
    "        input_mask_all.append(input_mask)\n",
    "        segment_ids_all.append([0] * max_seq_length)\n",
    "\n",
    "    return np.array(input_ids_all), np.array(input_mask_all), np.array(segment_ids_all)\n",
    "\n",
    "def encode(input_text):\n",
    "    input_ids, input_mask, segment_ids = create_input(\n",
    "    input_text, tokenizer, max_seq_length)\n",
    "    return labse_model([input_ids, input_mask, segment_ids])\n",
    "\n",
    "def construct_model(max_seq_length=64):\n",
    "    \n",
    "    model_dir = \"/linguistics/ethan/DL_Prototype/models/LaBSE_1\"\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:5\", \"/gpu:6\", \"/gpu:7\"])\n",
    "    with mirrored_strategy.scope():\n",
    "        labse_model, labse_layer = get_model(model_url=model_dir, \n",
    "                                             max_seq_length=max_seq_length)\n",
    "\n",
    "    vocab_file = labse_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "    do_lower_case = labse_layer.resolved_object.do_lower_case.numpy()\n",
    "    tokenizer = bert.bert_tokenization.FullTokenizer(vocab_file, do_lower_case)\n",
    "    \n",
    "    return labse_model, tokenizer\n",
    "\n",
    "def compute_embeddings(input_texts, tokenizer, max_seq_length, labse_model):\n",
    "    \n",
    "    input_ids, input_mask, segment_ids = create_input(input_texts, tokenizer, max_seq_length)\n",
    "    \n",
    "    return labse_model([input_ids, input_mask, segment_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:5', '/job:localhost/replica:0/task:0/device:GPU:6', '/job:localhost/replica:0/task:0/device:GPU:7')\n"
     ]
    }
   ],
   "source": [
    "max_seq_length=64\n",
    "labse_model, tokenizer = construct_model(max_seq_length)\n",
    "# model = hub.KerasLayer(\"\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"This is a test\", \"hello world\", \"give me a translation\"] * 50\n",
    "max_seq_length=64\n",
    "embedding = compute_embeddings(inputs, tokenizer, max_seq_length, labse_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa9086b7310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function recreate_function.<locals>.restored_function_body at 0x7fa9086b7310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filepath = \"/linguistics/ethan/DL_Prototype/datasets/TB_TQA/Unlabeled/Human_QA_finance_202102.tb_extracted.10k.xlsx\"\n",
    "df = pd.read_excel(filepath)\n",
    "en_embedding_one = compute_embeddings(df[\"source\"].to_numpy()[:2000], tokenizer, max_seq_length, labse_model)\n",
    "fr_embedding_one = compute_embeddings(df[\"target\"].to_numpy()[:2000], tokenizer, max_seq_length, labse_model)\n",
    "\n",
    "en_embedding_two = compute_embeddings(df[\"source\"].to_numpy()[2000:], tokenizer, max_seq_length, labse_model)\n",
    "fr_embedding_two = compute_embeddings(df[\"target\"].to_numpy()[2000:], tokenizer, max_seq_length, labse_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embedding = tf.concat([en_embedding_one, en_embedding_two], axis=0)\n",
    "fr_embedding = tf.concat([fr_embedding_one, fr_embedding_two], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4932, 768)\n",
      "(4932, 768)\n"
     ]
    }
   ],
   "source": [
    "print(en_embedding.shape)\n",
    "print(fr_embedding.shape)\n",
    "import pickle, json\n",
    "filepath = \"/linguistics/ethan/DL_Prototype/datasets/TB_TQA/Unlabeled/tb_extracted_20210526.5k.pkl\"\n",
    "data_dict = {\"en_texts\": df[\"source\"].to_numpy(),\n",
    "             \"fr_texts\": df[\"target\"].to_numpy(),\n",
    "             \"en_embedding\": en_embedding,\n",
    "             \"fr_embedding\": fr_embedding}\n",
    "\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
